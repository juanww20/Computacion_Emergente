{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1566d650",
   "metadata": {},
   "source": [
    "## Informacion que se puede modificar en el codigo para ver como cambia los resultados de prediccion\n",
    "\n",
    "Aqu√≠ tienes un desglose de las perillas que puedes mover, agrupadas por su funci√≥n.\n",
    "\n",
    "1. ‚öôÔ∏è Perillas del Modelo (El RandomForestClassifier)\n",
    "Aqu√≠ es donde ajustas el \"cerebro\" del modelo. Es lo primero que deber√≠as modificar.\n",
    "\n",
    "- n_estimators: (N√∫mero de √Årboles)\n",
    "\n",
    "    - Qu√© es: Cu√°ntos √°rboles de decisi√≥n individuales se construyen. T√∫ usaste 100.\n",
    "\n",
    "    - Efecto: M√°s √°rboles generalmente hacen que el modelo sea m√°s robusto y preciso, pero tambi√©n m√°s lento de entrenar. 100 es un buen inicio, pero 300 o 500 podr√≠an capturar m√°s patrones. Hay un punto de \"retorno decreciente\" donde m√°s √°rboles no ayudan mucho m√°s.\n",
    "\n",
    "    - Prueba: Cambia n_estimators=100 por n_estimators=300.\n",
    "\n",
    "- max_depth: (Profundidad M√°xima del √Årbol)\n",
    "\n",
    "    - Qu√© es: Qu√© tan \"profundo\" o \"complejo\" puede ser cada √°rbol. Por defecto (None), los √°rboles crecen hasta que son puros, lo cual puede llevar a memorizar los datos (sobreajuste).\n",
    "\n",
    "    - Efecto: Esta es la perilla m√°s importante para controlar el sobreajuste. Un max_depth m√°s bajo (ej. 5 o 10) fuerza al modelo a ser m√°s simple y generalizar mejor.\n",
    "\n",
    "    - Prueba: A√±ade max_depth=10 a los par√°metros de tu RandomForestClassifier.\n",
    "\n",
    "- min_samples_leaf: (Muestras M√≠nimas por Hoja)\n",
    "\n",
    "    - Qu√© es: El n√∫mero m√≠nimo de estudiantes que deben terminar en una \"hoja\" final del √°rbol. El valor por defecto es 1.\n",
    "\n",
    "    - Efecto: Al igual que max_depth, esto controla el sobreajuste. Poner min_samples_leaf=5 significa que el modelo no puede crear una regla s√∫per espec√≠fica para un solo estudiante; cualquier regla debe aplicar al menos a 5 estudiantes.\n",
    "\n",
    "    - Prueba: A√±ade min_samples_leaf=5 a tus par√°metros.\n",
    "\n",
    "2. üîÄ Perillas de la Divisi√≥n de Datos (El train_test_split)\n",
    "Aqu√≠ defines tu \"campo de juego\": cu√°nto usas para entrenar y cu√°nto para probar.\n",
    "\n",
    "- test_size: (Tama√±o del Conjunto de Prueba)\n",
    "\n",
    "    - Qu√© es: El porcentaje de tus datos que guardas para el examen final. Usaste 0.2 (20%).\n",
    "\n",
    "    - Efecto: Es un balance.\n",
    "\n",
    "        - Menos test_size (ej. 0.1): M√°s datos para entrenar (el modelo puede aprender m√°s), pero tu evaluaci√≥n (la precisi√≥n) es menos confiable porque se basa en menos datos de prueba.\n",
    "\n",
    "        - M√°s test_size (ej. 0.3): Menos datos para entrenar (el modelo podr√≠a ser m√°s d√©bil), pero tu evaluaci√≥n es m√°s robusta.\n",
    "\n",
    "    - Prueba: 0.2 o 0.25 son est√°ndares de la industria. Puedes dejarlo as√≠ por ahora.\n",
    "\n",
    "- random_state: (Semilla de Aleatoriedad)\n",
    "\n",
    "    - Qu√© es: Es el n√∫mero de \"semilla\" que usa la funci√≥n para barajar y dividir los datos. T√∫ usaste 42.\n",
    "\n",
    "    - Efecto: Esto es para la reproducibilidad. Mientras mantengas random_state=42, siempre obtendr√°s exactamente la misma divisi√≥n de datos (y por lo tanto, resultados muy similares), lo cual es VITAL para comparar si tus cambios en n_estimators o max_depth realmente mejoraron algo.\n",
    "\n",
    "    - Prueba: NO LO CAMBIES mientras est√©s ajustando el modelo. C√°mbialo solo al final (ej. a random_state=123) para verificar que tu resultado de 0.72 no fue solo una \"casualidad\" de esa divisi√≥n espec√≠fica.\n",
    "\n",
    "3. üî¨ Perillas de los Datos (El Preprocesamiento)\n",
    "Estos son cambios m√°s avanzados que modifican la informaci√≥n que le das al modelo.\n",
    "\n",
    "- El Umbral del Objetivo:\n",
    "\n",
    "    - Qu√© es: Definiste \"Alto Consumo\" como df['Walc'] > 2.\n",
    "\n",
    "    - Efecto: ¬øY si el problema fuera predecir \"Consumo Extremo\" (df['Walc'] > 3)? Esto cambia fundamentalmente el problema. Tambi√©n cambiar√° el balance de tus clases (tendr√°s menos '1' y m√°s '0'), lo que afectar√° el recall.\n",
    "\n",
    "    - Prueba: Es un cambio conceptual. Mantenlo en > 2 por ahora, a menos que quieras resolver una pregunta de negocio diferente.\n",
    "\n",
    "- Ingenier√≠a de Caracter√≠sticas (Feature Engineering):\n",
    "\n",
    "    - Qu√© es: Crear nuevas columnas a partir de las existentes.\n",
    "\n",
    "    - Efecto: A veces, una combinaci√≥n de caracter√≠sticas es m√°s predictiva que las caracter√≠sticas solas."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
